# Kubenetes简介

k8s 是谷歌在2014年开源的容器化集群管理系统，让部署容器化应用更加简洁和高效。
 
特点：
- 轻量级： 消耗资源小
- 开源
- 弹性伸缩
- 负载均衡 ： IPVS



## 基础概念

- Pod:  控制器类型  K8S 网络通讯模式 

- 资源清单： 资源清单的语法   编写 Pod   掌握 Pod 的生命周期

- Pod 控制器：各种控制器的特点以及使用定义方式

- 服务发现： SVC 原理及其构建方式

- 存储：多种存储类型的特点 并且能够在不同环境中选择合适的存储方案

- 调度器：调度器原理  根据要求把Pod 定义到想要的节点运行

- 安全：集群的认证  鉴权  访问控制 原理及其流程 

- HELM：(Linux yum)   掌握 HELM 原理   HELM 模板自定义  HELM 部署一些常用插件

- 运维：修改Kubeadm 达到证书可用期限为 10年   能够构建高可用的 Kubernetes 集群


## k8s功能

### 自动装箱

基于容器对应用运行环境的资源配置要求自动部署应用容器

### 自我修复(自愈能力)

当容器失败时，会对容器进行重启

当所部署的Node节点有问题时，会对容器进行重新部署和重新调度

当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务

![image-20200928101336750](/blog/devops/k8s/image-20200928101336750.png)

如果某个服务器上的应用不响应了，Kubernetes会自动在其它的地方创建一个

![image-20201122112241092](/blog/devops/k8s/image-20201122112241092.png)

### 水平扩展

通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁

> 当我们有大量的请求来临时，我们可以增加副本数量，从而达到水平扩展的效果

当黄色应用过度忙碌，会来扩展一个应用

![image-20201122112301750](/blog/devops/k8s/image-20201122112301750.png)

### 服务发现

用户不需使用额外的服务发现机制，就能够基于Kubernetes 自身能力实现服务发现和负载均衡

> 对外提供统一的入口，让它来做节点的调度和负载均衡， 相当于微服务里面的网关？

![image-20200928101711968](/blog/devops/k8s/image-20200928101711968.png)

### 滚动更新

可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新

> 添加应用的时候，不是加进去就马上可以进行使用，而是需要判断这个添加进去的应用是否能够正常使用

### 版本回退

可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退

> 类似于Git中的回滚

### 密钥和配置管理

在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。

### 存储编排

自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要

存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务

### 批处理

提供一次性任务，定时任务；满足批量数据处理和分析的场景



## 基础组件

![image-20200928103059652.png](/blog/devops/k8s/image-20200928103059652.png)

### API Server
所有服务访问统一入口

### Crontroller Manager
维持副本期望数目

### Scheduler
负责介绍任务，选择合适的节点进行分配任务

### ETCD
键值对数据库  储存K8S集群所有重要信息（持久化）

### Kubelet
直接跟容器引擎交互实现容器的生命周期管理

### Kube-proxy
负责写入规则至 IPTABLES、IPVS 实现服务映射访问的

### Docker
容器


## 扩展组件

### CoreDNS
可以为集群中的SVC创建一个域名IP的对应关系解析

### Dashboard
给 K8S 集群提供一个 B/S 结构访问体系

### Ingress Controller
官方只能实现四层代理，INGRESS 可以实现七层代理

### Federation
提供一个可以跨集群中心多K8S统一管理功能

### Promethueus
提供K8S集群的监控能力

### ELK
提供 K8S 集群日志统一分析接入平台



## 流程
![image-20201122163512535](/blog/devops/k8s/image-20201122163512535.png)

- 通过Kubectl提交一个创建RC（Replication Controller）的请求，该请求通过APlserver写入etcd
- 此时Controller Manager通过API Server的监听资源变化的接口监听到此RC事件
- 分析之后，发现当前集群中还没有它所对应的Pod实例
- 于是根据RC里的Pod模板定义一个生成Pod对象，通过APIServer写入etcd
- 此事件被Scheduler发现，它立即执行执行一个复杂的调度流程，为这个新的Pod选定一个落户的Node，然后通过API Server讲这一结果写入etcd中
- 目标Node上运行的Kubelet进程通过APiserver监测到这个"新生的Pod.并按照它的定义，启动该Pod并任劳任怨地负责它的下半生，直到Pod的生命结束
- 随后，我们通过Kubectl提交一个新的映射到该Pod的Service的创建请求
- ControllerManager通过Label标签查询到关联的Pod实例，然后生成Service的Endpoints信息，并通过APIServer写入到etod中，
- 接下来，所有Node上运行的Proxy进程通过APIServer查询并监听Service对象与其对应的Endponts信息，建立一个软件方式的负载均衡器来实现Service访问到后端Pod的流量转发功能
